# Vision-course-project

Artificial neural networks have proven to be powerful atidentifying patterns between the distributions of input andoutput data. However, if an input is not within the distribu-tion that the model was trained on, and hence the model isunsure which class it belongs to, the model should be ableto ”reject” to classify it rather than guessing with low con-fidence.  In conventional neural networks, the values of theparameters after training are fixed scalars that the modeluses to classify inputs.  Hence, given a fixed input, the net-work will always classify it identically.  On the other hand,in the Bayesian context, each parameter is a random vari-able with an associated probability distribution.   As a re-sult,  training  each  parameter  distribution  initiates  with  aprior distribution and updates its latent variables, the meanand  the  standard  deviation.   Once  trained,  the  values  ofthe  parameters  are  sampled  from  the  corresponding  dis-tributions,  allowing the model to make different inferencefor an identical input.  This project compares the trainingprocess and evaluates the performance difference betweenconventional and Bayesian neural networks.  To highlight,the Bayesian neural network containing one hidden layerwith  the  ability  to  reject  to  classify  achieved  65.69%  in-ference accuracy on the CIFAR-10 dataset [2], whereas aconventional fully connected neural network with the samedepth achieved 30.84% and a convolutional neural networkachieved 45.79%.
